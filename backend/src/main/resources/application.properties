# Server Configuration
server.port=8080
spring.application.name=qa-automation-service-hub

# WebFlux Configuration
spring.webflux.base-path=/

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=always
management.info.env.enabled=true

# Spring Boot Admin
spring.boot.admin.client.url=http://localhost:8081
spring.boot.admin.client.instance.management-url=http://localhost:8080/actuator
spring.boot.admin.client.instance.health-url=http://localhost:8080/actuator/health

# Logging Configuration
logging.level.com.maheshgaire.qaautomation=DEBUG
logging.level.org.springframework.web=INFO
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n

# CORS Configuration is handled in CorsConfig.java

# Application Info
info.app.name=QA Automation Service Hub
info.app.description=Backend APIs for QA automation utilities
info.app.version=1.0.0
info.app.author=Mahesh Gaire

# Free AI Configuration
ai.service.provider=huggingface
# Options: mock, ollama, huggingface, gemini
# mock = No external calls, intelligent mock responses
# ollama = Local Ollama server (completely free)
# huggingface = Free tier API
# gemini = Google's free tier

# Ollama Configuration (Local AI - completely free)
ai.ollama.base-url=http://localhost:11434
ai.ollama.model=llama2
ai.ollama.timeout=30000

# Hugging Face Configuration (Free tier)
ai.huggingface.api-key=${HF_API_KEY:demo-mode}
ai.huggingface.model=microsoft/DialoGPT-medium
ai.huggingface.base-url=https://api-inference.huggingface.co

# AI Analysis Settings
ai.max-tokens=1000
ai.temperature=0.7
ai.mock-responses=true